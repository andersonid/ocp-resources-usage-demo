<!DOCTYPE html>
<html lang="pt-BR">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Workshop - Dimensionamento e Scaling no OpenShift</title>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/dist/reveal.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/dist/theme/black.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/plugin/highlight/monokai.css">
<style>
  :root {
    --r-background-color: #1a1a2e;
    --r-main-color: #e0e0e0;
    --r-heading-color: #ffffff;
    --r-link-color: #ee0000;
    --red: #cc0000;
    --green: #2e7d32;
    --blue: #1565c0;
    --yellow: #f9a825;
    --orange: #e65100;
  }
  .reveal { font-size: 28px; }
  .reveal h1 { font-size: 2.2em; color: var(--red); }
  .reveal h2 { font-size: 1.6em; color: #fff; border-bottom: 2px solid var(--red); padding-bottom: 10px; }
  .reveal h3 { font-size: 1.2em; color: #ccc; }
  .reveal .slide-number { font-size: 14px; }
  .reveal table { font-size: 0.75em; margin: 0 auto; }
  .reveal table th { background: var(--red); color: #fff; padding: 8px 14px; }
  .reveal table td { padding: 6px 14px; border-bottom: 1px solid #444; }
  .reveal pre { font-size: 0.65em; }
  .reveal code { font-size: 0.9em; }
  .reveal .slides section { text-align: left; }
  .reveal .slides section.center { text-align: center; }
  .reveal img.slide-img { max-height: 55vh; border: none; box-shadow: none; background: transparent; }
  .badge-red { background: var(--red); color: #fff; padding: 4px 12px; border-radius: 4px; font-weight: bold; font-size: 0.8em; }
  .badge-green { background: var(--green); color: #fff; padding: 4px 12px; border-radius: 4px; font-weight: bold; font-size: 0.8em; }
  .badge-blue { background: var(--blue); color: #fff; padding: 4px 12px; border-radius: 4px; font-weight: bold; font-size: 0.8em; }
  .badge-yellow { background: var(--yellow); color: #000; padding: 4px 12px; border-radius: 4px; font-weight: bold; font-size: 0.8em; }
  .demo-indicator { background: var(--orange); color: #fff; padding: 6px 16px; border-radius: 6px; font-size: 0.9em; display: inline-block; margin-top: 10px; }
  .key-message { border-left: 4px solid var(--red); padding: 15px 20px; background: rgba(204,0,0,0.1); margin: 15px 0; font-style: italic; }
  .two-col { display: flex; gap: 30px; }
  .two-col > div { flex: 1; }
  .fragment.highlight-red.visible { color: var(--red); }
  ul { margin-left: 0; }
  li { margin-bottom: 8px; }
  .demo-btn {
    display: inline-block; padding: 8px 18px; margin: 5px 4px; border-radius: 6px;
    color: #fff; text-decoration: none; font-size: 0.8em; font-weight: bold;
    transition: opacity 0.2s;
  }
  .demo-btn:hover { opacity: 0.85; color: #fff; }
  .demo-btn.red    { background: var(--red); }
  .demo-btn.green  { background: var(--green); }
  .demo-btn.blue   { background: var(--blue); }
  .demo-btn.orange { background: var(--orange); }
  .demo-btn.dark   { background: #444; }
  .demo-btn.disabled { background: #555; cursor: not-allowed; opacity: 0.5; }
  .demo-links { margin-top: 15px; }
</style>
</head>
<body>
<div class="reveal">
<div class="slides">

<!-- ============================================================ -->
<!-- TITLE -->
<!-- ============================================================ -->
<section class="center" data-background-color="#0e0e1a">
  <img src="images/redhat-logo.svg" alt="Red Hat" style="width:180px; margin-bottom:20px;">
  <h1 style="font-size:1.8em">Dimensionamento e Scaling<br>de Aplicações no OpenShift</h1>
  <p style="color:#999; margin-top:30px;">Workshop Energisa | Red Hat</p>
  <p style="color:#666; font-size:0.7em; margin-top:40px;">Pressione <kbd style="background:#333;padding:2px 8px;border-radius:3px">S</kbd> para ver as notas do apresentador<br>
  Use as <kbd style="background:#333;padding:2px 8px;border-radius:3px">setas</kbd> para navegar</p>
  <div class="demo-links" style="margin-top:30px;" id="title-links">
    <a class="demo-btn blue"   href="https://console-openshift-console.__CLUSTER_DOMAIN__" target="_blank">Console OpenShift</a>
    <a class="demo-btn orange" href="https://console-openshift-console.__CLUSTER_DOMAIN__/terminal" target="_blank">Web Terminal</a>
    <a class="demo-btn dark"   href="https://openshift-gitops-server-openshift-gitops.__CLUSTER_DOMAIN__" target="_blank">Argo CD</a>
    <a class="demo-btn dark"   href="https://multicloud-console.__CLUSTER_DOMAIN__" target="_blank">ACM Console</a>
  </div>
  <aside class="notes">
    Bom dia a todos. Esse workshop tem como objetivo mostrar na prática como dimensionar corretamente aplicações no OpenShift,
    evitando desperdício de recursos e garantindo que autoscaling funcione de verdade.
    Vamos começar com um pouco de contexto histórico para entender de onde viemos.
    Os botões acima abrem as ferramentas do cluster em nova aba.
  </aside>
</section>

<!-- ============================================================ -->
<!-- PART 0 - EVOLUÇÃO DOS RECURSOS COMPUTACIONAIS -->
<!-- ============================================================ -->
<section>
  <section class="center">
    <h2>Recursos Computacionais</h2>
    <h3>A Evolução</h3>
    <aside class="notes">
      Antes de falar de Kubernetes e OpenShift, vamos relembrar como chegamos até aqui.
      A história dos recursos computacionais passa por várias fases, e cada uma trouxe avanços e novos problemas.
    </aside>
  </section>

  <section class="center">
    <img src="images/01-old-way-single.png" class="slide-img" alt="The old way - single app">
    <aside class="notes">
      Como era antes? Até mesmo antes da virtualização.
      Você tinha na sua infra um servidor com sua CPU e memória, o sistema operacional, e a sua aplicação rodava em cima desse SO e HW.
      Qual era o problema aqui? Se você tivesse uma aplicação que não estivesse usando todo o HW, você tinha um desperdício dos recursos computacionais.
      Então você precisava otimizar o uso desses recursos.
    </aside>
  </section>

  <section class="center">
    <img src="images/02-old-way-multi.png" class="slide-img" alt="The old way - multiple apps">
    <aside class="notes">
      Como começou a otimizar? Colocar mais de uma aplicação no mesmo servidor.
      Qual o problema disso? Uma aplicação tinha acesso às mesmas coisas que as outras.
      Além disso, a Aplicação A pode consumir recursos da Aplicação B e gerar perda de performance de ambas.
      Você tinha melhor aproveitamento do HW, mas não tinha isolamento entre as aplicações.
    </aside>
  </section>

  <section class="center">
    <img src="images/03-virtualization.png" class="slide-img" alt="Virtualization">
    <aside class="notes">
      Qual foi a primeira solução que apareceu? Virtualização.
      Você passa a ter ambientes segregados, onde nesta máquina virtual você tem um sistema operacional e suas bibliotecas específicas para aquela aplicação.
      E você consegue isolar todos os recursos computacionais para aquela aplicação, bem como limitar a quantidade de HW.
      Mas isso ainda gera problemas. Por quê? Você ainda tem um overhead de ter outro SO.
      O hypervisor nada mais é do que outro SO, e você acaba tendo essa sobreposição -- um SO em cima do outro. Não é o melhor dos cenários.
    </aside>
  </section>

  <section class="center">
    <img src="images/04-cgroups.png" class="slide-img" alt="cgroups">
    <aside class="notes">
      A próxima evolução: cgroups. Isolamento e limites de recursos por aplicação, no mesmo sistema operacional.
      Você usa o SO diretamente no HW físico, isolando suas aplicações, mas ainda compartilhando as bibliotecas.
      O que são cgroups? Um recurso do kernel Linux que limita, contabiliza e isola o uso de CPU, memória, IO de disco e rede de um conjunto de processos.
      Os cgroups são um componente-chave dos containers -- e é por isso que conseguimos implementar requests e limits no Kubernetes.
      Basicamente, cgroups são o mecanismo que permite ao Kubernetes controlar quanto de CPU e memória cada container pode usar.
    </aside>
  </section>

  <section class="center">
    <img src="images/05-containers.png" class="slide-img" alt="Containers - cgroups + namespaces">
    <aside class="notes">
      Então começamos a usar cgroups mais namespaces do Linux. Namespaces são um recurso do kernel que particiona
      os recursos de forma que um conjunto de processos vê um conjunto de recursos, enquanto outro conjunto vê um conjunto diferente.
      Aqui, com os containers, já conseguimos manter as bibliotecas isoladas e customizadas por aplicação.
      Cada container tem seu próprio filesystem, sua rede, seus processos. Isolamento completo, sem o overhead de uma VM inteira.
    </aside>
  </section>

  <section class="center">
    <img src="images/06-container-virtualization.png" class="slide-img" alt="Container + Virtualization">
    <aside class="notes">
      Hoje em dia, trabalhamos com o melhor dos dois mundos: containers rodando dentro de VMs.
      No slide anterior, ainda usamos a infra inteira do nó. Se ocorrer um incidente como um bug de kernel, pode onerar o nó todo.
      Desse jeito, você cria máquinas virtuais específicas e customizadas, e coloca suas aplicações ali.
      É onde entra o Kubernetes e o OpenShift -- orquestrando tudo isso: recursos computacionais, nós, containers.
      E é exatamente sobre como configurar corretamente esses recursos que vamos falar agora.
    </aside>
  </section>
</section>

<!-- ============================================================ -->
<!-- PART 1 - O PROBLEMA REAL -->
<!-- ============================================================ -->
<section>
  <section>
    <h2>Parte 1 -- O Problema Real</h2>
    <p style="color:#999;">~10 minutos</p>
    <aside class="notes">
      Agora que contextualizamos a evolução, vamos falar do problema concreto que vemos no dia a dia dos clusters.
    </aside>
  </section>

  <section>
    <h2>Padrões que se repetem</h2>
    <div class="fragment">
      <p><span class="badge-red">Tipo 1</span> Requests de CPU inflados</p>
      <p style="color:#999;font-size:0.85em;">Deployments pedem 300m, 500m, até 1000m. Uso real: 1m a 10m. Reservando 50x a 100x mais.</p>
    </div>
    <div class="fragment">
      <p><span class="badge-red">Tipo 2</span> Requests = Limits (QoS Guaranteed)</p>
      <p style="color:#999;font-size:0.85em;">Impede o Kubernetes de reaproveitar recursos ociosos. Faz sentido para bancos de dados, não para microsserviços.</p>
    </div>
    <div class="fragment">
      <p><span class="badge-red">Tipo 3</span> Multiplicação do problema</p>
      <p style="color:#999;font-size:0.85em;">50 microsserviços x 300m de request cada = 15 vCPUs reservadas. Uso real: 250m.</p>
    </div>
    <aside class="notes">
      Analisando clusters reais, identificamos padrões que se repetem em praticamente todos os clientes.
      Não vou apontar nomes -- o objetivo não é auditar ninguém, é mostrar oportunidades de melhoria.
      O impacto disso é concreto: o scheduler acha que os nodes estão cheios e pede mais nodes.
      O HPA nunca dispara. O cluster precisa de mais capacidade, mais subscrições, mais custo -- para rodar a mesma carga.
    </aside>
  </section>

  <section>
    <h2>O impacto concreto</h2>
    <ul>
      <li>O scheduler acha que os nodes estão <strong>cheios</strong></li>
      <li>O HPA <strong>nunca dispara</strong> -- o denominador (request) é gigante</li>
      <li>O cluster pede mais nodes = <strong>mais custo</strong></li>
      <li>Pods ficam em <strong>Pending</strong> por "Insufficient cpu" com nodes ociosos</li>
    </ul>
    <div class="key-message fragment">
      Isso não é culpa de ninguém. É um padrão comum. A mentalidade de "coloca recursos altos pra não dar problema"
      faz sentido para quem desenvolve, mas tem um custo real na plataforma.
    </div>
    <aside class="notes">
      É exatamente isso que vamos resolver hoje. Vou mostrar na prática o que acontece, como identificar, e como corrigir.
    </aside>
  </section>
</section>

<!-- ============================================================ -->
<!-- PART 2 - FUNDAMENTOS TÉCNICOS -->
<!-- ============================================================ -->
<section>
  <section>
    <h2>Parte 2 -- Fundamentos Técnicos</h2>
    <p style="color:#999;">~20 minutos</p>
  </section>

  <section>
    <h2>Scheduler vs Runtime</h2>
    <div class="two-col">
      <div>
        <h3><span class="badge-blue">Scheduler</span></h3>
        <ul>
          <li>Decide <strong>onde</strong> o pod roda</li>
          <li>Olha os <strong>requests</strong></li>
          <li>Requests = <strong>reserva</strong></li>
          <li>Não sabe o uso real</li>
        </ul>
      </div>
      <div>
        <h3><span class="badge-yellow">Runtime (kubelet)</span></h3>
        <ul>
          <li>Controla <strong>o consumo</strong></li>
          <li>Olha os <strong>limits</strong></li>
          <li>Limits = <strong>teto</strong></li>
          <li>Usa cgroups para impor</li>
        </ul>
      </div>
    </div>
    <aside class="notes">
      Para entender o problema, precisamos entender dois momentos distintos.
      Primeiro, o Scheduler. Quando você cria um Deployment, ele olha os requests e procura um node com capacidade.
      Segundo, o Runtime -- kubelet e cgroups. Depois que o pod está rodando, quem controla é o kubelet.
      Se o pod ultrapassar o limit de CPU, é throttled. Se ultrapassar memória, é OOMKilled.
    </aside>
  </section>

  <section>
    <h2>CPU vs Memória</h2>
    <table>
      <thead><tr><th>Aspecto</th><th>CPU</th><th>Memória</th></tr></thead>
      <tbody>
        <tr><td>Tipo</td><td><span class="badge-green">Compressível</span></td><td><span class="badge-red">Incompressível</span></td></tr>
        <tr><td>No limit</td><td>Throttling (mais lento)</td><td>OOMKill (morto)</td></tr>
        <tr><td>Pod sobrevive?</td><td>Sim</td><td>Não</td></tr>
        <tr><td>Kernel toma de volta?</td><td>Sim, reduz ciclos</td><td>Não, mata o processo</td></tr>
        <tr><td>Impacto no usuário</td><td>Latência maior</td><td>Erro 500 / conexão perdida</td></tr>
      </tbody>
    </table>
    <aside class="notes">
      CPU é compressível -- o kernel limita ciclos sem matar. O pod fica lento mas continua vivo.
      Memória é incompressível -- uma vez alocada, o kernel não toma de volta sem matar.
      Essa diferença é crítica para entender por que o HPA funciona para CPU mas não para memória.
    </aside>
  </section>

  <section>
    <h2>Requests, Limits e QoS</h2>
    <table>
      <thead><tr><th></th><th>Guaranteed</th><th>Burstable</th><th>BestEffort</th></tr></thead>
      <tbody>
        <tr><td>Configuração</td><td>req = limit</td><td>req &lt; limit</td><td>nenhum</td></tr>
        <tr><td>Burst?</td><td>Não</td><td>Sim</td><td>Ilimitado</td></tr>
        <tr><td>Eviction</td><td>Último</td><td>Médio</td><td>Primeiro</td></tr>
        <tr><td>Ideal para</td><td>DB, Kafka</td><td>Microsserviços</td><td>Jobs descartáveis</td></tr>
        <tr><td>HPA funciona?</td><td>Quase impossível</td><td>Sim</td><td>N/A</td></tr>
      </tbody>
    </table>
    <div class="key-message fragment">
      Guaranteed não significa "garante mais recursos". Significa que o pod tem um contrato fixo --
      nunca consome mais nem menos. Em troca, é o último a ser removido sob pressão.
    </div>
    <aside class="notes">
      O Kubernetes atribui automaticamente uma classe de QoS baseada na relação entre requests e limits.
      Guaranteed tranca recursos. Burstable permite burst. Para microsserviços, Burstable é quase sempre o caminho certo.
      Analogia: Guaranteed é reservar uma mesa de 10 lugares para jantar sozinho.
      Burstable é reservar 1 lugar e usar as cadeiras ao lado se estiverem vazias.
    </aside>
  </section>

  <section>
    <h2>Comparação direta</h2>
    <table>
      <thead><tr><th>Aspecto</th><th style="color:#f44336">Guaranteed (2000m/2000m)</th><th style="color:#4caf50">Burstable (50m/200m)</th></tr></thead>
      <tbody>
        <tr><td>Reserva no scheduler</td><td>2000m (2 vCPUs)</td><td>50m</td></tr>
        <tr><td>Máximo que pode usar</td><td>2000m</td><td>200m</td></tr>
        <tr><td>Pods num node 8 vCPU</td><td>~4</td><td>~160</td></tr>
        <tr><td>CPU desperdiçada idle</td><td>~1995m trancados</td><td>~45m trancados</td></tr>
        <tr><td>HPA funciona?</td><td>Quase impossível</td><td>Sim</td></tr>
      </tbody>
    </table>
    <aside class="notes">
      Esses são exatamente os nossos dois apps de demonstração. app-ruim com 2000m/2000m e app-bom com 50m/200m.
      O mesmo teto de segurança pode ser atingido com Burstable -- a diferença é que não tranca recursos no scheduler.
    </aside>
  </section>

  <section>
    <h2>Os manifestos dos nossos apps</h2>
    <div class="demo-indicator">DEMO -- Abrir terminal</div>
    <div class="demo-links">
      <a class="demo-btn orange" href="https://console-openshift-console.__CLUSTER_DOMAIN__/terminal" target="_blank">Abrir Web Terminal</a>
    </div>
    <div class="two-col" style="margin-top:20px;">
      <div>
        <h3 style="color:#f44336">app-ruim</h3>
        <pre><code class="yaml">resources:
  requests:
    cpu: "2"
    memory: 2Gi
  limits:
    cpu: "2"
    memory: 2Gi</code></pre>
        <p style="font-size:0.75em;color:#f44336">QoS: Guaranteed | HPA: morto</p>
      </div>
      <div>
        <h3 style="color:#4caf50">app-bom</h3>
        <pre><code class="yaml">resources:
  requests:
    cpu: 50m
    memory: 128Mi
  limits:
    cpu: 200m
    memory: 256Mi</code></pre>
        <p style="font-size:0.75em;color:#4caf50">QoS: Burstable | HPA: funcional</p>
      </div>
    </div>
    <aside class="notes">
      Vamos olhar no terminal. Dois namespaces: app-ruim e app-bom. Mesma aplicação, mesma imagem. A única diferença são os recursos.
      Executar: oc get deployment stress-app -n app-ruim -o yaml | grep -A 8 resources
      E depois: oc get deployment stress-app -n app-bom -o yaml | grep -A 8 resources
    </aside>
  </section>

  <section>
    <h2>Vendo no Resource Dashboard</h2>
    <div class="demo-indicator">DEMO -- Abrir Resource Dashboard</div>
    <div class="demo-links">
      <a class="demo-btn green" href="https://resource-dashboard-demo-dashboard.__CLUSTER_DOMAIN__" target="_blank">Abrir Resource Dashboard</a>
    </div>
    <ul style="margin-top:20px;">
      <li><span style="color:#f44336">Lado esquerdo (vermelho)</span>: app-ruim -- uso real ~0%, requests ocupam tudo</li>
      <li><span style="color:#4caf50">Lado direito (verde)</span>: app-bom -- proporção saudável</li>
      <li>HPA do app-ruim: 0% de CPU. Target 70% = 1400m. <strong>Nunca vai disparar.</strong></li>
      <li>HPA do app-bom: 2% de CPU. Target 70% = 35m. <strong>Vai funcionar.</strong></li>
    </ul>
    <aside class="notes">
      Abrir o Resource Dashboard. Mostrar os dois lados.
      Apontar para o CPU atual dos dois: 0% no ruim, 2% no bom.
      Explicar: os dois consomem o mesmo CPU absoluto em idle (~1m). A diferença é o denominador.
      1m / 2000m = 0%. 1m / 50m = 2%. O HPA trabalha com essa porcentagem.
    </aside>
  </section>
</section>

<!-- ============================================================ -->
<!-- PART 3 - AUTOSCALING AO VIVO -->
<!-- ============================================================ -->
<section>
  <section>
    <h2>Parte 3 -- Autoscaling ao Vivo</h2>
    <p style="color:#999;">~25 minutos</p>
    <div class="demo-indicator">DEMO INTERATIVA</div>
    <div class="demo-links" style="margin-top:20px;">
      <a class="demo-btn green" href="https://stress-app-app-bom.__CLUSTER_DOMAIN__" target="_blank">Abrir Stress App (app-bom)</a>
      <a class="demo-btn red"   href="https://stress-app-app-ruim.__CLUSTER_DOMAIN__" target="_blank">Abrir Stress App (app-ruim)</a>
      <a class="demo-btn blue"  href="https://resource-dashboard-demo-dashboard.__CLUSTER_DOMAIN__" target="_blank">Abrir Dashboard</a>
    </div>
  </section>

  <section>
    <h2>Gerando carga no app-bom</h2>
    <div class="demo-indicator">DEMO -- Stress App app-bom</div>
    <div class="demo-links">
      <a class="demo-btn green" href="https://stress-app-app-bom.__CLUSTER_DOMAIN__" target="_blank">Abrir Stress App (app-bom)</a>
    </div>
    <ol style="margin-top:20px;">
      <li>Abrir Stress App do app-bom</li>
      <li>Clicar em <strong>"120s - Moderado"</strong></li>
      <li>Voltar ao Dashboard -- observar CPU subindo</li>
      <li>HPA detecta carga &gt; 70% e escala</li>
      <li>Novas réplicas aparecem</li>
    </ol>
    <div class="key-message fragment">
      Isso é autoscaling funcionando de verdade. Requests corretos = HPA funcional.
    </div>
    <aside class="notes">
      Disparar 2 minutos de carga moderada no app-bom. Voltar ao dashboard e observar.
      A CPU sobe, ultrapassa 70% do request (35m), e o HPA escala.
      Se perguntarem por que só um pod mostra CPU alta: o teste gera carga internamente no pod.
      Não é tráfego distribuído. Em produção, o Route distribui entre réplicas.
    </aside>
  </section>

  <section>
    <h2>Gerando carga no app-ruim</h2>
    <div class="demo-indicator">DEMO -- Stress App app-ruim</div>
    <div class="demo-links">
      <a class="demo-btn red" href="https://stress-app-app-ruim.__CLUSTER_DOMAIN__" target="_blank">Abrir Stress App (app-ruim)</a>
    </div>
    <ol style="margin-top:20px;">
      <li>Mesma carga, mesma aplicação</li>
      <li>CPU sobe em milicores...</li>
      <li>Mas a <strong>porcentagem</strong> fica ridiculamente baixa</li>
      <li>HPA vê 5%, 10%... longe dos 70%</li>
      <li><strong>Zero réplicas novas</strong></li>
    </ol>
    <div class="key-message fragment">
      Mesma aplicação. Mesma carga. Mesmo HPA. A única diferença são os requests.
      Esse é exatamente o cenário que acontece em clusters reais.
    </div>
    <aside class="notes">
      Mesma coisa no app-ruim. Mesma carga, mas o request é 2000m.
      A porcentagem de CPU nunca chega perto de 70% (que seria 1400m!).
      O HPA está efetivamente morto.
    </aside>
  </section>

  <section>
    <h2>OOMKill -- Limits de Memória</h2>
    <div class="demo-indicator">DEMO -- Stress App</div>
    <div class="demo-links">
      <a class="demo-btn red"   href="https://stress-app-app-ruim.__CLUSTER_DOMAIN__" target="_blank">app-ruim</a>
      <a class="demo-btn green" href="https://stress-app-app-bom.__CLUSTER_DOMAIN__" target="_blank">app-bom</a>
    </div>
    <ul style="margin-top:20px;">
      <li>Memória é <strong>incompressível</strong> -- não tem throttle, tem OOMKill</li>
      <li>Alocar memória progressivamente com <strong>+64 MB</strong></li>
      <li>Observar a barra: verde &rarr; amarela &rarr; vermelha pulsando</li>
      <li>No limit: <strong>OOMKilled</strong> -- pod reiniciado</li>
    </ul>
    <aside class="notes">
      No app-ruim, limit de 2Gi. Clicar em +64MB repetidamente até estourar.
      No app-bom, limit de 256Mi. Mostrar que com menos alocação já fica na zona vermelha.
      O ponto: limits protegem o node. Requests dimensionados corretamente + limits com margem = configuração ideal.
    </aside>
  </section>
</section>

<!-- ============================================================ -->
<!-- PART 4 - OBSERVABILIDADE -->
<!-- ============================================================ -->
<section>
  <section>
    <h2>Parte 4 -- Observabilidade</h2>
    <p style="color:#999;">~10 minutos</p>
    <div class="demo-indicator">DEMO -- CLI + Console OpenShift</div>
    <div class="demo-links" style="margin-top:15px;">
      <a class="demo-btn orange" href="https://console-openshift-console.__CLUSTER_DOMAIN__/terminal" target="_blank">Web Terminal</a>
      <a class="demo-btn blue"   href="https://console-openshift-console.__CLUSTER_DOMAIN__/monitoring/dashboards" target="_blank">Observe &gt; Dashboards</a>
    </div>
  </section>

  <section>
    <h2>CLI -- Comandos essenciais</h2>
    <pre><code class="bash"># Uso real de CPU/memória
oc adm top pods -n app-bom
oc adm top pods -n app-ruim

# Status do HPA
oc get hpa -n app-bom
oc get hpa -n app-ruim

# Alocação do node (requests acumulados)
oc describe node | grep -A 5 "Allocated resources"</code></pre>
    <aside class="notes">
      Mostrar esses comandos no terminal/Web Terminal.
      O ponto crítico é o Allocated resources -- mostra a soma dos requests de todos os pods no node.
      Quanto mais inflado, mais rápido o node "lota" na visão do scheduler.
    </aside>
  </section>

  <section>
    <h2>Console -- Dashboards nativos</h2>
    <div class="demo-indicator">DEMO -- OpenShift Console &gt; Observe &gt; Dashboards</div>
    <div class="demo-links">
      <a class="demo-btn blue" href="https://console-openshift-console.__CLUSTER_DOMAIN__/monitoring/dashboards" target="_blank">Abrir Dashboards</a>
    </div>
    <ul style="margin-top:20px;">
      <li><strong>Kubernetes / Compute Resources / Namespace (Pods)</strong></li>
      <li>CPU Usage -- consumo real ao longo do tempo</li>
      <li>CPU Quota -- uso vs requests vs limits (folga de burst)</li>
      <li>Memory Usage -- consumo de memória</li>
      <li>Selecionar app-bom, depois app-ruim -- comparar visualmente</li>
    </ul>
    <div class="key-message fragment">
      Esses dashboards já existem no cluster. Não precisa instalar nada.
      Use-os periodicamente para identificar desperdício.
    </div>
    <aside class="notes">
      Navegar para Observe > Dashboards > Kubernetes / Compute Resources / Namespace (Pods).
      Selecionar app-bom primeiro, depois app-ruim. Mostrar a diferença visual.
      Também mostrar o dashboard de Cluster para a visão geral.
    </aside>
  </section>
</section>

<!-- ============================================================ -->
<!-- PART 5 - HPA -->
<!-- ============================================================ -->
<section>
  <section>
    <h2>HPA -- Horizontal Pod Autoscaler</h2>
    <p style="color:#999;">Conceitos-chave</p>
  </section>

  <section>
    <h2>A fórmula do HPA</h2>
    <pre style="font-size:0.9em;text-align:center;background:#222;padding:20px;border-radius:8px;"><code>réplicas = ceil( atuais x (métrica_atual / métrica_target) )</code></pre>
    <table style="margin-top:20px;">
      <thead><tr><th>Cenário</th><th>Request</th><th>Uso real</th><th>%</th><th>HPA dispara?</th></tr></thead>
      <tbody>
        <tr style="color:#4caf50"><td>app-bom</td><td>50m</td><td>80m</td><td>160%</td><td>Sim (3 réplicas)</td></tr>
        <tr style="color:#f44336"><td>app-ruim</td><td>2000m</td><td>80m</td><td>4%</td><td>Não</td></tr>
      </tbody>
    </table>
    <div class="key-message fragment">
      O request é o denominador. Se é gigante, a porcentagem nunca sobe.
    </div>
    <aside class="notes">
      A fórmula é simples: uso dividido por request = porcentagem.
      O HPA calcula sobre o request, NÃO sobre o limit.
      Com request de 50m, 80m de uso dá 160%. Com request de 2000m, dá 4%.
    </aside>
  </section>

  <section>
    <h2>Por que NÃO usar HPA para memória?</h2>
    <ol>
      <li>Carga sobe &rarr; pod aloca memória &rarr; HPA escala</li>
      <li>Carga diminui &rarr; pods <strong>não liberam memória</strong> (GC não devolve ao SO)</li>
      <li>HPA calcula que ainda precisa das réplicas (% continua alta)</li>
      <li>Réplicas nunca são removidas &rarr; HPA <strong>travado</strong></li>
    </ol>
    <div class="key-message fragment">
      CPU é compressível -- o kernel faz throttle e libera. Funciona com HPA.<br>
      Memória é incompressível -- uma vez alocada, não volta. Use VPA.
    </div>
    <aside class="notes">
      Memória é incompressível. O garbage collector não devolve memória ao SO quando a carga diminui.
      Por isso o HPA para memória fica travado -- as réplicas nunca são removidas.
      Para memória, a solução é o VPA.
    </aside>
  </section>
</section>

<!-- ============================================================ -->
<!-- PART 5B - VPA -->
<!-- ============================================================ -->
<section>
  <section>
    <h2>Parte 5 -- VPA</h2>
    <h3>Descobrindo os valores certos</h3>
    <p style="color:#999;">~15 minutos</p>
  </section>

  <section>
    <h2>O que é o VPA</h2>
    <div class="key-message">
      O VPA observa o comportamento real da aplicação ao longo de dias e <strong>recomenda</strong>
      os valores ideais de CPU e memória. Transforma o "chute" em decisão baseada em dados.
    </div>
    <table style="margin-top:20px;">
      <thead><tr><th>Componente</th><th>Função</th></tr></thead>
      <tbody>
        <tr><td><strong>Recommender</strong></td><td>Calcula recomendações baseado em métricas</td></tr>
        <tr><td><strong>Updater</strong></td><td>Marca pods para reinício (modos Auto/Recreate)</td></tr>
        <tr><td><strong>Admission Controller</strong></td><td>Injeta valores em novos pods</td></tr>
      </tbody>
    </table>
    <aside class="notes">
      O VPA responde a pergunta: qual o valor certo?
      Em vez de chutar requests e limits, você coleta dados reais por dias e usa as recomendações.
    </aside>
  </section>

  <section>
    <h2>Simulador de Carga</h2>
    <div class="demo-indicator">DEMO -- Abrir Simulador de Carga</div>
    <div class="demo-links">
      <a class="demo-btn blue" href="https://workload-simulator-vpa-demo.__CLUSTER_DOMAIN__" target="_blank">Abrir Simulador de Carga</a>
    </div>
    <ul style="margin-top:20px;">
      <li>Aplicação rodando há dias com carga oscilante</li>
      <li>60 min pico (~65 usuários) + 60 min fora de pico (~10 usuários)</li>
      <li>VPA em modo <strong>Off</strong> -- apenas observando</li>
      <li>Configurada com 1000m CPU / 1Gi memória (propositalmente inflado)</li>
    </ul>
    <aside class="notes">
      Abrir o Simulador de Carga. Mostrar o gráfico oscilando.
      Depois, no terminal, mostrar os resources atuais e as recomendações do VPA.
    </aside>
  </section>

  <section>
    <h2>Recomendações do VPA</h2>
    <div class="demo-indicator">DEMO -- Terminal: oc describe vpa</div>
    <div class="demo-links">
      <a class="demo-btn orange" href="https://console-openshift-console.__CLUSTER_DOMAIN__/terminal" target="_blank">Web Terminal</a>
    </div>
    <table style="margin-top:20px;">
      <thead><tr><th>Campo</th><th>Significado</th><th>Uso prático</th></tr></thead>
      <tbody>
        <tr><td><strong>Target</strong></td><td>Valor ideal (p90)</td><td>Use como <strong>requests</strong></td></tr>
        <tr><td><strong>Lower Bound</strong></td><td>Mínimo seguro</td><td>Nunca vá abaixo disso</td></tr>
        <tr><td><strong>Upper Bound</strong></td><td>Picos observados</td><td>Referência para <strong>limits</strong></td></tr>
        <tr><td><strong>Uncapped Target</strong></td><td>Target sem restrições</td><td>Diagnóstico do resourcePolicy</td></tr>
      </tbody>
    </table>
    <aside class="notes">
      Usar o botão Copiar no Simulador de Carga ou executar diretamente:
      oc describe vpa vpa-workload-simulator -n vpa-demo | grep -A 20 "Container Recommendations"
      Comparar os valores recomendados com os 1000m/1Gi configurados.
    </aside>
  </section>

  <section>
    <h2>Modos do VPA</h2>
    <table>
      <thead><tr><th>Modo</th><th>Comportamento</th><th>Risco</th></tr></thead>
      <tbody>
        <tr><td><span class="badge-green">Off</span></td><td>Apenas recomenda</td><td>Zero</td></tr>
        <tr><td><span class="badge-blue">Initial</span></td><td>Aplica em novos pods</td><td>Baixo</td></tr>
        <tr><td><span class="badge-yellow">Auto</span></td><td>Aplica e reinicia pods</td><td>Médio (use PDB)</td></tr>
      </tbody>
    </table>
    <div class="key-message fragment">
      Comece sempre com Off. Colete dados por 7 dias. Analise. Depois avance.
    </div>
    <aside class="notes">
      O VPA em modo Off é uma ferramenta de auditoria. Mostra onde está o desperdício sem alterar nada.
      VPA + HPA se complementam: VPA descobre o tamanho certo, HPA escala horizontalmente com esses valores.
    </aside>
  </section>
</section>

<!-- ============================================================ -->
<!-- PART 6 - BOAS PRÁTICAS -->
<!-- ============================================================ -->
<section>
  <section>
    <h2>Parte 6 -- Boas Práticas</h2>
  </section>

  <section>
    <h2>Regras de ouro</h2>
    <ol>
      <li><strong>Requests = uso médio observado</strong> (p50-p75)</li>
      <li><strong>Limits de CPU = 2x a 4x</strong> o request (margem de burst)</li>
      <li><strong>Limits de memória = 1.5x a 2x</strong> o request (OOMKill é destrutivo)</li>
      <li><strong>Nunca requests = limits</strong> exceto para workloads críticos stateful</li>
      <li><strong>Use VPA modo Off</strong> para calibrar com dados reais</li>
      <li><strong>Defina LimitRanges</strong> para impedir configurações extremas</li>
      <li><strong>Monitore continuamente</strong> com dashboards nativos</li>
    </ol>
  </section>
</section>

<!-- ============================================================ -->
<!-- PART 7 - ROUTE VS SERVICE -->
<!-- ============================================================ -->
<section>
  <section>
    <h2>Parte 7 -- Route vs Service</h2>
    <h3>Comunicação interna</h3>
    <p style="color:#999;">~10 minutos</p>
    <div class="demo-indicator">DEMO INTERATIVA</div>
    <div class="demo-links" style="margin-top:15px;">
      <a class="demo-btn red"   href="https://stress-app-app-ruim.__CLUSTER_DOMAIN__" target="_blank">app-ruim (Via Route)</a>
      <a class="demo-btn green" href="https://stress-app-app-bom.__CLUSTER_DOMAIN__" target="_blank">app-bom (Via Service)</a>
    </div>
  </section>

  <section>
    <h2>O anti-pattern</h2>
    <div class="two-col">
      <div>
        <h3 style="color:#f44336">Via Route (errado)</h3>
        <p style="font-size:0.75em;">Pod A &rarr; Router HAProxy &rarr; DNS externo &rarr; TLS &rarr; Router &rarr; Pod B</p>
        <p><strong>6 hops | ~20ms</strong></p>
      </div>
      <div>
        <h3 style="color:#4caf50">Via Service (correto)</h3>
        <p style="font-size:0.75em;">Pod A &rarr; OVN/cluster SDN &rarr; Pod B</p>
        <p><strong>2 hops | ~5ms</strong></p>
      </div>
    </div>
    <table style="margin-top:20px;font-size:0.75em;">
      <thead><tr><th>Cenário</th><th>Use</th></tr></thead>
      <tbody>
        <tr><td>Acesso externo (browsers, APIs públicas)</td><td><strong>Route</strong></td></tr>
        <tr><td>Entre pods no mesmo namespace</td><td><strong>Service</strong> (nome:porta)</td></tr>
        <tr><td>Entre pods em namespaces diferentes</td><td><strong>Service</strong> (nome.ns.svc.cluster.local:porta)</td></tr>
      </tbody>
    </table>
    <div class="key-message fragment">
      Route é a porta de entrada. Não o corredor interno.
    </div>
    <aside class="notes">
      Outro anti-pattern comum: apps se comunicando entre namespaces usando a URL da Route.
      Demonstrar nos stress-apps: Via Route no app-ruim (~20ms) vs Via Service no app-bom (~5ms).
      2x a 3x mais lento. Em produção com centenas de microsserviços, cada chamada via Route adiciona carga no Router.
    </aside>
  </section>
</section>

<!-- ============================================================ -->
<!-- PART 8 - GITOPS E POLICIES -->
<!-- ============================================================ -->
<section>
  <section>
    <h2>Parte 8 -- Protegendo o Cluster</h2>
    <h3>GitOps + Policies</h3>
    <p style="color:#999;">~15 minutos</p>
    <div class="demo-links" style="margin-top:15px;">
      <a class="demo-btn dark"   href="https://openshift-gitops-server-openshift-gitops.__CLUSTER_DOMAIN__" target="_blank">Argo CD</a>
      <a class="demo-btn dark"   href="https://multicloud-console.__CLUSTER_DOMAIN__" target="_blank">ACM Console</a>
      <a class="demo-btn orange" href="https://console-openshift-console.__CLUSTER_DOMAIN__/terminal" target="_blank">Web Terminal</a>
    </div>
  </section>

  <section>
    <h2>Três camadas de proteção</h2>
    <table>
      <thead><tr><th>Camada</th><th>Ferramenta</th><th>Responsabilidade</th></tr></thead>
      <tbody>
        <tr><td><span class="badge-blue">CI</span></td><td>Tekton Pipelines</td><td>Padroniza o build</td></tr>
        <tr><td><span class="badge-green">CD</span></td><td>Argo CD (GitOps)</td><td>Git é a fonte de verdade</td></tr>
        <tr><td><span class="badge-yellow">Governança</span></td><td>ACM Policies</td><td>Audita e reporta violações</td></tr>
      </tbody>
    </table>
    <div class="key-message fragment">
      Pipeline padroniza o build. GitOps protege o deploy. Policies garantem conformidade.
      Três camadas, zero "oc edit".
    </div>
    <aside class="notes">
      Cada camada tem uma responsabilidade. Juntas, formam uma defesa em profundidade.
      Dev entrega código, pipeline cria imagem, ArgoCD deploya do Git, ACM audita.
    </aside>
  </section>

  <section>
    <h2>ACM Governance -- Policies</h2>
    <div class="demo-indicator">DEMO -- ACM Console &gt; Governance</div>
    <div class="demo-links">
      <a class="demo-btn dark" href="https://multicloud-console.__CLUSTER_DOMAIN__/multicloud/governance/policies" target="_blank">Abrir ACM Governance</a>
    </div>
    <table style="margin-top:20px;font-size:0.8em;">
      <thead><tr><th>Policy</th><th>Status</th><th>Quem viola</th></tr></thead>
      <tbody>
        <tr><td>policy-resource-ceiling</td><td><span class="badge-red">NonCompliant</span></td><td>app-ruim (2 CPU &gt; teto 1 CPU)</td></tr>
        <tr><td>policy-required-labels</td><td><span class="badge-red">NonCompliant</span></td><td>app-ruim (faltam labels)</td></tr>
        <tr><td>policy-no-guaranteed-stateless</td><td><span class="badge-red">NonCompliant</span></td><td>app-ruim (req = lim)</td></tr>
      </tbody>
    </table>
    <aside class="notes">
      Abrir ACM Console > Governance > Policies. Mostrar as 3 policies.
      Clicar em cada uma e mostrar qual cluster, namespace e recurso está violando.
      A policy não pune -- ela ilumina. Sem policies, ninguém sabe que tem problema.
    </aside>
  </section>

  <section>
    <h2>Correção via GitOps</h2>
    <div class="demo-indicator">DEMO -- Git commit + Argo CD sync</div>
    <div class="demo-links">
      <a class="demo-btn dark" href="https://openshift-gitops-server-openshift-gitops.__CLUSTER_DOMAIN__" target="_blank">Abrir Argo CD</a>
    </div>
    <ol style="margin-top:20px;">
      <li>Corrigir labels no Git (<code>gitops/app-bom/deployment.yaml</code>)</li>
      <li>Commit e push</li>
      <li>Argo CD sincroniza automaticamente</li>
      <li>ACM: app-bom fica <span class="badge-green">Compliant</span></li>
    </ol>
    <div class="key-message fragment">
      A correção veio pelo Git. Ninguém fez "oc edit".
      O Git é a fonte de verdade e a policy validou automaticamente.
    </div>
    <aside class="notes">
      Demonstrar: editar o deployment no Git, adicionar labels, commit e push.
      Mostrar no ArgoCD o sync. Voltar ao ACM e mostrar que app-bom ficou Compliant.
    </aside>
  </section>

  <section>
    <h2>Argo CD selfHeal</h2>
    <div class="demo-indicator">DEMO -- Delete + auto-recovery</div>
    <div class="demo-links">
      <a class="demo-btn dark"   href="https://openshift-gitops-server-openshift-gitops.__CLUSTER_DOMAIN__" target="_blank">Argo CD</a>
      <a class="demo-btn orange" href="https://console-openshift-console.__CLUSTER_DOMAIN__/terminal" target="_blank">Web Terminal</a>
    </div>
    <ol style="margin-top:20px;">
      <li>Mostrar que app-bom está Synced e Healthy no ArgoCD</li>
      <li>Simular acidente: <code>oc delete route stress-app -n app-bom</code></li>
      <li>ArgoCD detecta drift e <strong>recria automaticamente</strong></li>
      <li>Status volta para Synced + Healthy</li>
    </ol>
    <div class="key-message fragment">
      Mesmo que alguém com cluster-admin apague recursos, o ArgoCD restaura baseado no Git.
      Se um script destrutivo fosse executado num cluster com GitOps, os recursos voltariam automaticamente.
    </div>
    <aside class="notes">
      Essa demo conecta com o incidente real do cliente -- script com oc delete que quebrou o cluster.
      Deletar um recurso, aguardar 10-30 segundos, mostrar o ArgoCD restaurando.
      Narrativa: com GitOps, isso não teria causado downtime permanente.
    </aside>
  </section>
</section>

<!-- ============================================================ -->
<!-- PART 9 - FECHAMENTO -->
<!-- ============================================================ -->
<section>
  <section>
    <h2>Fechamento</h2>
    <h3>Próximos passos</h3>
  </section>

  <section>
    <h2>O que vimos hoje</h2>
    <ul>
      <li><strong>Por que acontece</strong> -- requests inflados reservam recursos que nunca são usados</li>
      <li><strong>O impacto real</strong> -- HPA travado, nodes "cheios" com uso de 5%, custo desnecessário</li>
      <li><strong>Como corrigir</strong> -- requests reais, limits com margem, QoS Burstable</li>
      <li><strong>Como descobrir os valores certos</strong> -- VPA modo Off por 7 dias</li>
      <li><strong>Como monitorar</strong> -- dashboards nativos do OpenShift</li>
      <li><strong>Como proteger</strong> -- GitOps + Policies = automação, não documentação</li>
    </ul>
  </section>

  <section>
    <h2>Próximos passos concretos</h2>
    <ol>
      <li><strong>Deployar VPA modo Off</strong> nos projetos críticos</li>
      <li><strong>Coletar métricas por 7 dias</strong> sem alterar nada</li>
      <li><strong>Analisar recomendações</strong> vs valores atuais</li>
      <li><strong>Ajustar gradualmente</strong> -- começando pelo maior desperdício</li>
      <li><strong>Revisar comunicação entre namespaces</strong> -- Routes vs Services</li>
    </ol>
    <div class="key-message fragment">
      Não é um projeto de meses. É uma mudança de configuração, deployment por deployment,
      com dados concretos guiando cada decisão.
    </div>
  </section>

  <section class="center">
    <img src="images/redhat-logo.svg" alt="Red Hat" style="width:120px; margin-bottom:20px;">
    <h1 style="font-size:2em">Obrigado!</h1>
    <p style="margin-top:30px;color:#999;">Perguntas?</p>
  </section>
</section>

</div><!-- .slides -->
</div><!-- .reveal -->

<script src="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/dist/reveal.js"></script>
<script src="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/plugin/notes/notes.js"></script>
<script src="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/plugin/highlight/highlight.js"></script>
<script>
Reveal.initialize({
  hash: true,
  slideNumber: 'c/t',
  showSlideNumber: 'all',
  transition: 'slide',
  transitionSpeed: 'fast',
  controlsTutorial: false,
  progress: true,
  center: false,
  width: 1280,
  height: 720,
  margin: 0.05,
  plugins: [ RevealNotes, RevealHighlight ]
});

// Disable demo buttons if cluster domain is not set
document.addEventListener('DOMContentLoaded', function() {
  var links = document.querySelectorAll('.demo-btn');
  links.forEach(function(link) {
    if (link.href && link.href.indexOf('__CLUSTER_DOMAIN__') !== -1) {
      link.classList.add('disabled');
      link.removeAttribute('href');
      link.title = 'Domínio do cluster não detectado';
    }
  });
});
</script>
</body>
</html>
